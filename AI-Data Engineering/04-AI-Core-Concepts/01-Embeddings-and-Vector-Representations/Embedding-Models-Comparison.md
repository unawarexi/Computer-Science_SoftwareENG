# ğŸ“Š Embedding Models Comparison

## Overview

This document provides a comprehensive comparison of popular embedding models to help you choose the right one for your use case.

---

## ğŸ† Top Embedding Models (2024-2025)

### OpenAI Models

| Model | Dimensions | Max Tokens | Best For | Cost |
|-------|------------|------------|----------|------|
| `text-embedding-3-large` | 3072 | 8191 | Highest accuracy | $0.00013/1K tokens |
| `text-embedding-3-small` | 1536 | 8191 | Balance of cost/performance | $0.00002/1K tokens |
| `text-embedding-ada-002` | 1536 | 8191 | Legacy, still reliable | $0.0001/1K tokens |

### Open Source Models

| Model | Dimensions | Max Tokens | Best For | Size |
|-------|------------|------------|----------|------|
| `all-MiniLM-L6-v2` | 384 | 256 | Fast, lightweight | 80MB |
| `all-mpnet-base-v2` | 768 | 384 | Better accuracy | 420MB |
| `e5-large-v2` | 1024 | 512 | High quality | 1.3GB |
| `bge-large-en-v1.5` | 1024 | 512 | MTEB leader | 1.3GB |
| `instructor-xl` | 768 | 512 | Task-specific | 4.9GB |

### Multilingual Models

| Model | Dimensions | Languages | Best For |
|-------|------------|-----------|----------|
| `multilingual-e5-large` | 1024 | 100+ | Cross-lingual search |
| `paraphrase-multilingual-MiniLM-L12-v2` | 384 | 50+ | Lightweight multilingual |
| `LaBSE` | 768 | 109 | Language-agnostic |

### Specialized Models

| Model | Dimensions | Specialization |
|-------|------------|----------------|
| `CodeBERT` | 768 | Code understanding |
| `StarEncoder` | 768 | Code search |
| `PubMedBERT` | 768 | Biomedical text |
| `LegalBERT` | 768 | Legal documents |
| `FinBERT` | 768 | Financial text |

---

## ğŸ“ˆ Performance Benchmarks (MTEB)

The Massive Text Embedding Benchmark (MTEB) scores:

| Model | Average Score | Retrieval | Clustering | Classification |
|-------|--------------|-----------|------------|----------------|
| text-embedding-3-large | 64.6 | 59.2 | 49.0 | 75.5 |
| bge-large-en-v1.5 | 64.2 | 59.5 | 48.8 | 75.3 |
| e5-large-v2 | 62.4 | 57.8 | 47.2 | 73.1 |
| all-mpnet-base-v2 | 57.8 | 49.4 | 43.7 | 65.2 |
| all-MiniLM-L6-v2 | 56.3 | 42.0 | 41.9 | 63.1 |

---

## ğŸ¯ Model Selection Guide

### By Use Case

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    WHICH MODEL TO USE?                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Production + High Accuracy?
    â””â”€â”€ YES â†’ text-embedding-3-large
    â””â”€â”€ NO  â†’ Continue...

Need Multilingual?
    â””â”€â”€ YES â†’ multilingual-e5-large
    â””â”€â”€ NO  â†’ Continue...

Budget Constrained?
    â””â”€â”€ YES â†’ text-embedding-3-small (API) or bge-large (local)
    â””â”€â”€ NO  â†’ Continue...

Local/Private Deployment?
    â””â”€â”€ YES â†’ bge-large-en-v1.5 or e5-large-v2
    â””â”€â”€ NO  â†’ text-embedding-3-small

Speed Critical?
    â””â”€â”€ YES â†’ all-MiniLM-L6-v2
    â””â”€â”€ NO  â†’ all-mpnet-base-v2

Domain Specific?
    â””â”€â”€ Code â†’ CodeBERT/StarEncoder
    â””â”€â”€ Medical â†’ PubMedBERT
    â””â”€â”€ Legal â†’ LegalBERT
    â””â”€â”€ Finance â†’ FinBERT
```

### By Constraints

| Constraint | Recommended Model |
|------------|-------------------|
| Lowest latency | all-MiniLM-L6-v2 |
| Lowest cost | text-embedding-3-small |
| Best accuracy | text-embedding-3-large |
| No API dependency | bge-large-en-v1.5 |
| Edge/mobile | all-MiniLM-L6-v2 |
| Long documents | text-embedding-3-large (8K tokens) |

---

## ğŸ’» Implementation Examples

### OpenAI

```python
from openai import OpenAI

client = OpenAI()

def embed_openai(texts, model="text-embedding-3-small"):
    response = client.embeddings.create(
        input=texts,
        model=model
    )
    return [d.embedding for d in response.data]
```

### Sentence Transformers (Local)

```python
from sentence_transformers import SentenceTransformer

# Load model
model = SentenceTransformer('BAAI/bge-large-en-v1.5')

def embed_local(texts):
    return model.encode(texts, normalize_embeddings=True)
```

### Cohere

```python
import cohere

co = cohere.Client('your-api-key')

def embed_cohere(texts, model="embed-english-v3.0"):
    response = co.embed(
        texts=texts,
        model=model,
        input_type="search_document"
    )
    return response.embeddings
```

### Voyage AI

```python
import voyageai

vo = voyageai.Client()

def embed_voyage(texts, model="voyage-2"):
    result = vo.embed(texts, model=model)
    return result.embeddings
```

---

## ğŸ“Š Cost Comparison (per 1M tokens)

| Provider | Model | Cost |
|----------|-------|------|
| OpenAI | text-embedding-3-small | $0.02 |
| OpenAI | text-embedding-3-large | $0.13 |
| Cohere | embed-english-v3.0 | $0.10 |
| Voyage AI | voyage-2 | $0.10 |
| Local | Any open source | $0 (compute only) |

---

## ğŸ”„ Dimension Reduction

Some models support dimension reduction for efficiency:

```python
from openai import OpenAI

client = OpenAI()

# Reduce dimensions from 3072 to 256
response = client.embeddings.create(
    input="Your text",
    model="text-embedding-3-large",
    dimensions=256  # Reduced dimensions
)
```

Benefits:
- Faster similarity search
- Lower storage costs
- Slight accuracy trade-off

---

## ğŸ“š Key Takeaways

1. **OpenAI text-embedding-3-small** - Best balance for most use cases
2. **bge-large-en-v1.5** - Best open-source option
3. **all-MiniLM-L6-v2** - Best for speed/edge deployment
4. **Consider domain-specific models** - When working in specialized fields
5. **Test on your data** - Benchmarks don't always reflect your specific use case
